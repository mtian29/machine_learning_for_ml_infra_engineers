{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "word_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZBRUaiBBEpa"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "YS3NA-i6nAFC"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SN5USFEIIK3"
      },
      "source": [
        "# Word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aojnnc7sXrab"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/word_embeddings\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/word_embeddings.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/word_embeddings.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/word_embeddings.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6mJg1g3apaz"
      },
      "source": [
        "This tutorial contains an introduction to word embeddings. You will train your own word embeddings using a simple Keras model for a sentiment classification task, and then visualize them in the [Embedding Projector](http://projector.tensorflow.org) (shown in the image below). \n",
        "\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/embedding.jpg?raw=1\" alt=\"Screenshot of the embedding projector\" width=\"400\"/>\n",
        "\n",
        "## Representing text as numbers\n",
        "\n",
        "Machine learning models take vectors (arrays of numbers) as input. When working with text, the first thing you must do is come up with a strategy to convert strings to numbers (or to \"vectorize\" the text) before feeding it to the model. In this section, you will look at three strategies for doing so.\n",
        "\n",
        "### One-hot encodings\n",
        "\n",
        "As a first idea, you might \"one-hot\" encode each word in your vocabulary. Consider the sentence \"The cat sat on the mat\". The vocabulary (or unique words) in this sentence is (cat, mat, on, sat, the). To represent each word, you will create a zero vector with length equal to the vocabulary, then place a one in the index that corresponds to the word. This approach is shown in the following diagram.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/one-hot.png?raw=1\" alt=\"Diagram of one-hot encodings\" width=\"400\" />\n",
        "\n",
        "To create a vector that contains the encoding of the sentence, you could then concatenate the one-hot vectors for each word.\n",
        "\n",
        "Key point: This approach is inefficient. A one-hot encoded vector is sparse (meaning, most indices are zero). Imagine you have 10,000 words in the vocabulary. To one-hot encode each word, you would create a vector where 99.99% of the elements are zero.\n",
        "\n",
        "### Encode each word with a unique number\n",
        "\n",
        "A second approach you might try is to encode each word using a unique number. Continuing the example above, you could assign 1 to \"cat\", 2 to \"mat\", and so on. You could then encode the sentence \"The cat sat on the mat\" as a dense vector like [5, 1, 4, 3, 5, 2]. This appoach is efficient. Instead of a sparse vector, you now have a dense one (where all elements are full).\n",
        "\n",
        "There are two downsides to this approach, however:\n",
        "\n",
        "* The integer-encoding is arbitrary (it does not capture any relationship between words).\n",
        "\n",
        "* An integer-encoding can be challenging for a model to interpret. A linear classifier, for example, learns a single weight for each feature. Because there is no relationship between the similarity of any two words and the similarity of their encodings, this feature-weight combination is not meaningful.\n",
        "\n",
        "### Word embeddings\n",
        "\n",
        "Word embeddings give us a way to use an efficient, dense representation in which similar words have a similar encoding. Importantly, you do not have to specify this encoding by hand. An embedding is a dense vector of floating point values (the length of the vector is a parameter you specify). Instead of specifying the values for the embedding manually, they are trainable parameters (weights learned by the model during training, in the same way a model learns weights for a dense layer). It is common to see word embeddings that are 8-dimensional (for small datasets), up to 1024-dimensions when working with large datasets. A higher dimensional embedding can capture fine-grained relationships between words, but takes more data to learn.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/embedding2.png?raw=1\" alt=\"Diagram of an embedding\" width=\"400\"/>\n",
        "\n",
        "Above is a diagram for a word embedding. Each word is represented as a 4-dimensional vector of floating point values. Another way to think of an embedding is as \"lookup table\". After these weights have been learned, you can encode each word by looking up the dense vector it corresponds to in the table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZUQErGewZxE"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RutaI-Tpev3T"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from datetime import datetime\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBFctV8-JZOc"
      },
      "source": [
        "### Download the IMDb Dataset\n",
        "You will use the [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/) through the tutorial. You will train a sentiment classifier model on this dataset and in the process learn embeddings from scratch. To read more about loading a dataset from scratch, see the [Loading text tutorial](../load_data/text.ipynb).  \n",
        "\n",
        "Download the dataset using Keras file utility and take a look at the directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPO4_UmfF0KH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9957d5cc-4eea-421a-e35e-aff4f598d5c2"
      },
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
        "                                    untar=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "os.listdir(dataset_dir)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imdbEr.txt', 'imdb.vocab', 'train', 'test', 'README']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1YOKTUgl2ldo",
        "outputId": "a168772b-8735-4e6c-916b-2046bacb899e"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./aclImdb_v1.tar.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY6yROZNKvbd"
      },
      "source": [
        "Take a look at the `train/` directory. It has `pos` and `neg` folders with movie reviews labelled as positive and negative respectively. You will use reviews from `pos` and `neg` folders to train a binary classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-iOHJGN6SDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2c3d60-28f5-41fb-8768-ed3a7c9cf88b"
      },
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['urls_pos.txt',\n",
              " 'pos',\n",
              " 'urls_neg.txt',\n",
              " 'urls_unsup.txt',\n",
              " 'neg',\n",
              " 'unsup',\n",
              " 'unsupBow.feat',\n",
              " 'labeledBow.feat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O59BdioK8jY"
      },
      "source": [
        "The `train` directory also has additional folders which should be removed before creating training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Vfi9oWMSh-"
      },
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFoJjiEyJz9u"
      },
      "source": [
        "Next, create a `tf.data.Dataset` using `tf.keras.preprocessing.text_dataset_from_directory`. You can read more about using this utility in this [text classification tutorial](https://www.tensorflow.org/tutorials/keras/text_classification). \n",
        "\n",
        "Use the `train` directory to create both train and validation datasets with a split of 20% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItYD3TLkCOP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207915a6-d87e-41d6-ef65-4f34936d66cc"
      },
      "source": [
        "batch_size = 1024\n",
        "seed = 123\n",
        "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=batch_size, validation_split=0.2, \n",
        "    subset='training', seed=seed)\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=batch_size, validation_split=0.2, \n",
        "    subset='validation', seed=seed)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYeDVT2c3PM1",
        "outputId": "7c922cf9-33b3-4a29-f4ab-aa6f2c403787"
      },
      "source": [
        "train_ds.take"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DatasetV2.take of <BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int32)>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHa6cq0-Ym0g"
      },
      "source": [
        "Take a look at a few movie reviews and their labels `(1: positive, 0: negative)` from the train dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTCbSkvkYmTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31dded0a-7f3c-4bd6-83a5-a9e374175ea7"
      },
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(5):\n",
        "    print(label_batch[i].numpy(), text_batch.numpy()[i])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 b\"Oh My God! Please, for the love of all that is holy, Do Not Watch This Movie! It it 82 minutes of my life I will never get back. Sure, I could have stopped watching half way through. But I thought it might get better. It Didn't. Anyone who actually enjoyed this movie is one seriously sick and twisted individual. No wonder us Australians/New Zealanders have a terrible reputation when it comes to making movies. Everything about this movie is horrible, from the acting to the editing. I don't even normally write reviews on here, but in this case I'll make an exception. I only wish someone had of warned me before I hired this catastrophe\"\n",
            "1 b'This movie is SOOOO funny!!! The acting is WONDERFUL, the Ramones are sexy, the jokes are subtle, and the plot is just what every high schooler dreams of doing to his/her school. I absolutely loved the soundtrack as well as the carefully placed cynicism. If you like monty python, You will love this film. This movie is a tad bit \"grease\"esk (without all the annoying songs). The songs that are sung are likable; you might even find yourself singing these songs once the movie is through. This musical ranks number two in musicals to me (second next to the blues brothers). But please, do not think of it as a musical per say; seeing as how the songs are so likable, it is hard to tell a carefully choreographed scene is taking place. I think of this movie as more of a comedy with undertones of romance. You will be reminded of what it was like to be a rebellious teenager; needless to say, you will be reminiscing of your old high school days after seeing this film. Highly recommended for both the family (since it is a very youthful but also for adults since there are many jokes that are funnier with age and experience.'\n",
            "0 b\"Alex D. Linz replaces Macaulay Culkin as the central figure in the third movie in the Home Alone empire. Four industrial spies acquire a missile guidance system computer chip and smuggle it through an airport inside a remote controlled toy car. Because of baggage confusion, grouchy Mrs. Hess (Marian Seldes) gets the car. She gives it to her neighbor, Alex (Linz), just before the spies turn up. The spies rent a house in order to burglarize each house in the neighborhood until they locate the car. Home alone with the chicken pox, Alex calls 911 each time he spots a theft in progress, but the spies always manage to elude the police while Alex is accused of making prank calls. The spies finally turn their attentions toward Alex, unaware that he has rigged devices to cleverly booby-trap his entire house. Home Alone 3 wasn't horrible, but probably shouldn't have been made, you can't just replace Macauley Culkin, Joe Pesci, or Daniel Stern. Home Alone 3 had some funny parts, but I don't like when characters are changed in a movie series, view at own risk.\"\n",
            "0 b\"There's a good movie lurking here, but this isn't it. The basic idea is good: to explore the moral issues that would face a group of young survivors of the apocalypse. But the logic is so muddled that it's impossible to get involved.<br /><br />For example, our four heroes are (understandably) paranoid about catching the mysterious airborne contagion that's wiped out virtually all of mankind. Yet they wear surgical masks some times, not others. Some times they're fanatical about wiping down with bleach any area touched by an infected person. Other times, they seem completely unconcerned.<br /><br />Worse, after apparently surviving some weeks or months in this new kill-or-be-killed world, these people constantly behave like total newbs. They don't bother accumulating proper equipment, or food. They're forever running out of fuel in the middle of nowhere. They don't take elementary precautions when meeting strangers. And after wading through the rotting corpses of the entire human race, they're as squeamish as sheltered debutantes. You have to constantly wonder how they could have survived this long... and even if they did, why anyone would want to make a movie about them.<br /><br />So when these dweebs stop to agonize over the moral dimensions of their actions, it's impossible to take their soul-searching seriously. Their actions would first have to make some kind of minimal sense.<br /><br />On top of all this, we must contend with the dubious acting abilities of Chris Pine. His portrayal of an arrogant young James T Kirk might have seemed shrewd, when viewed in isolation. But in Carriers he plays on exactly that same note: arrogant and boneheaded. It's impossible not to suspect that this constitutes his entire dramatic range.<br /><br />On the positive side, the film *looks* excellent. It's got an over-sharp, saturated look that really suits the southwestern US locale. But that can't save the truly feeble writing nor the paper-thin (and annoying) characters. Even if you're a fan of the end-of-the-world genre, you should save yourself the agony of watching Carriers.\"\n",
            "0 b'I saw this movie at an actual movie theater (probably the $2.00 one) with my cousin and uncle. We were around 11 and 12, I guess, and really into scary movies. I remember being so excited to see it because my cool uncle let us pick the movie (and we probably never got to do that again!) and sooo disappointed afterwards!! Just boring and not scary. The only redeeming thing I can remember was Corky Pigeon from Silver Spoons, and that wasn\\'t all that great, just someone I recognized. I\\'ve seen bad movies before and this one has always stuck out in my mind as the worst. This was from what I can recall, one of the most boring, non-scary, waste of our collective $6, and a waste of film. I have read some of the reviews that say it is worth a watch and I say, \"Too each his own\", but I wouldn\\'t even bother. Not even so bad it\\'s good.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHV2pchDhzDn"
      },
      "source": [
        "### Configure the dataset for performance\n",
        "\n",
        "These are two important methods you should use when loading data to make sure that I/O does not become blocking.\n",
        "\n",
        "`.cache()` keeps data in memory after it's loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files.\n",
        "\n",
        "`.prefetch()` overlaps data preprocessing and model execution while training. \n",
        "\n",
        "You can learn more about both methods, as well as how to cache data to disk in the [data performance guide](https://www.tensorflow.org/guide/data_performance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz6k1IW7h1TO"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqBazMiVQkj1"
      },
      "source": [
        "## Using the Embedding layer\n",
        "\n",
        "Keras makes it easy to use word embeddings. Take a look at the [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
        "\n",
        "The Embedding layer can be understood as a lookup table that maps from integer indices (which stand for specific words) to dense vectors (their embeddings). The dimensionality (or width) of the embedding is a parameter you can experiment with to see what works well for your problem, much in the same way you would experiment with the number of neurons in a Dense layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OjxLVrMvWUE"
      },
      "source": [
        "# Embed a 1,000 word vocabulary into 5 dimensions.\n",
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dKKV1L2Rk7e"
      },
      "source": [
        "When you create an Embedding layer, the weights for the embedding are randomly initialized (just like any other layer). During training, they are gradually adjusted via backpropagation. Once trained, the learned word embeddings will roughly encode similarities between words (as they were learned for the specific problem your model is trained on).\n",
        "\n",
        "If you pass an integer to an embedding layer, the result replaces each integer with the vector from the embedding table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YUjPgP7w0PO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b776786a-e02c-40ea-e3e3-349a1d685a01"
      },
      "source": [
        "result = embedding_layer(tf.constant([1,2,3]))\n",
        "result.numpy()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01757929,  0.00844295,  0.0446032 , -0.0409875 ,  0.00120318],\n",
              "       [-0.00602722,  0.01621229, -0.02351868, -0.02844862,  0.04445047],\n",
              "       [ 0.01782516, -0.04667405, -0.01095877, -0.01066915, -0.01797707]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4PC4QzsxTGx"
      },
      "source": [
        "For text or sequence problems, the Embedding layer takes a 2D tensor of integers, of shape `(samples, sequence_length)`, where each entry is a sequence of integers. It can embed sequences of variable lengths. You could feed into the embedding layer above batches with shapes `(32, 10)` (batch of 32 sequences of length 10) or `(64, 15)` (batch of 64 sequences of length 15).\n",
        "\n",
        "The returned tensor has one more axis than the input, the embedding vectors are aligned along the new last axis. Pass it a `(2, 3)` input batch and the output is `(2, 3, N)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwSYepRjyRGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1371111-13af-4fc8-d472-287248c55848"
      },
      "source": [
        "result = embedding_layer(tf.constant([[0,1,2],[3,4,5]]))\n",
        "result.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGQp2N92yOyB"
      },
      "source": [
        "When given a batch of sequences as input, an embedding layer returns a 3D floating point tensor, of shape `(samples, sequence_length, embedding_dimensionality)`. To convert from this sequence of variable length to a fixed representation there are a variety of standard approaches. You could use an RNN, Attention, or pooling layer before passing it to a Dense layer. This tutorial uses pooling because it's the simplest. The [Text Classification with an RNN](text_classification_rnn.ipynb) tutorial is a good next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGicgV5qT0wh"
      },
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6NZSqIIoU0Y"
      },
      "source": [
        "Next, define the dataset preprocessing steps required for your sentiment classification model. Initialize a TextVectorization layer with the desired parameters to vectorize movie reviews. You can learn more about using this layer in the [Text Classification](https://www.tensorflow.org/tutorials/keras/text_classification) tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MlsXzo-ZlfK"
      },
      "source": [
        "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "# Vocabulary size and number of words in a sequence.\n",
        "vocab_size = 10000\n",
        "sequence_length = 100\n",
        "\n",
        "# Use the text vectorization layer to normalize, split, and map strings to \n",
        "# integers. Note that the layer uses the custom standardization defined above. \n",
        "# Set maximum_sequence length as all samples are not of the same length.\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_ds = train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4XRRnSn54Ax",
        "outputId": "af3787f1-8e48-4c21-f9a1-f4c66fb128b5"
      },
      "source": [
        "vectorize_layer"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7f0af3d88f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI9_wLIiWO8Z"
      },
      "source": [
        "## Create a classification model\n",
        "\n",
        "Use the [Keras Sequential API](../../guide/keras) to define the sentiment classification model. In this case it is a \"Continuous bag of words\" style model.\n",
        "* The [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) layer transforms strings into vocabulary indices. You have already initialized `vectorize_layer` as a TextVectorization layer and built it's vocabulary by calling `adapt` on `text_ds`. Now vectorize_layer can be used as the first layer of your end-to-end classification model, feeding tranformed strings into the Embedding layer.\n",
        "* The [`Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: `(batch, sequence, embedding)`.\n",
        "\n",
        "* The [`GlobalAveragePooling1D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling1D) layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
        "\n",
        "* The fixed-length output vector is piped through a fully-connected ([`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) layer with 16 hidden units.\n",
        "\n",
        "* The last layer is densely connected with a single output node. \n",
        "\n",
        "Caution: This model doesn't use masking, so the zero-padding is used as part of the input and hence the padding length may affect the output.  To fix this, see the [masking and padding guide](../../guide/keras/masking_and_padding)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHLcFtn5Wsqj"
      },
      "source": [
        "embedding_dim=16\n",
        "\n",
        "model = Sequential([\n",
        "  vectorize_layer,\n",
        "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
        "  GlobalAveragePooling1D(),\n",
        "  Dense(16, activation='relu'),\n",
        "  Dense(1)\n",
        "])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjLNgKO7W2fe"
      },
      "source": [
        "## Compile and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpX9etB6IOQd"
      },
      "source": [
        "You will use [TensorBoard](https://www.tensorflow.org/tensorboard) to visualize metrics including loss and accuracy. Create a `tf.keras.callbacks.TensorBoard`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Hg3IHFt4Px"
      },
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OrKAKAKIbuH"
      },
      "source": [
        "Compile and train the model using the `Adam` optimizer and `BinaryCrossentropy` loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCUgdP69Wzix"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mQehiQyv8rP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9d7a91-5976-4000-96ce-ee9ac5eceb54"
      },
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds, \n",
        "    epochs=15,\n",
        "    callbacks=[tensorboard_callback])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 6s 199ms/step - loss: 0.6927 - accuracy: 0.5037 - val_loss: 0.6900 - val_accuracy: 0.4886\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.6888 - accuracy: 0.5037 - val_loss: 0.6839 - val_accuracy: 0.4886\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.6817 - accuracy: 0.5037 - val_loss: 0.6738 - val_accuracy: 0.4886\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.6703 - accuracy: 0.5037 - val_loss: 0.6591 - val_accuracy: 0.4886\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.6535 - accuracy: 0.5056 - val_loss: 0.6392 - val_accuracy: 0.5098\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 2s 87ms/step - loss: 0.6307 - accuracy: 0.5457 - val_loss: 0.6149 - val_accuracy: 0.5884\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.6027 - accuracy: 0.6317 - val_loss: 0.5875 - val_accuracy: 0.6508\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 2s 88ms/step - loss: 0.5710 - accuracy: 0.7073 - val_loss: 0.5589 - val_accuracy: 0.7030\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.5377 - accuracy: 0.7531 - val_loss: 0.5310 - val_accuracy: 0.7360\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.5047 - accuracy: 0.7840 - val_loss: 0.5052 - val_accuracy: 0.7534\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.4734 - accuracy: 0.8055 - val_loss: 0.4821 - val_accuracy: 0.7678\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 2s 92ms/step - loss: 0.4447 - accuracy: 0.8200 - val_loss: 0.4621 - val_accuracy: 0.7786\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.4188 - accuracy: 0.8321 - val_loss: 0.4451 - val_accuracy: 0.7872\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.3956 - accuracy: 0.8433 - val_loss: 0.4308 - val_accuracy: 0.7948\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.3749 - accuracy: 0.8504 - val_loss: 0.4189 - val_accuracy: 0.8010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0aea33f630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wYnVedSPfmX"
      },
      "source": [
        "With this approach the model reaches a validation accuracy of around 84% (note that the model is overfitting since training accuracy is higher).\n",
        "\n",
        "Note: Your results may be a bit different, depending on how weights were randomly initialized before training the embedding layer. \n",
        "\n",
        "You can look into the model summary to learn more about each layer of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDCgjWyq_0dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d501ac2-c8cd-4be9-d8e3-2d82825e7379"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization (TextVect (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 100, 16)           160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56lQcGRpgmRU",
        "outputId": "48ac6a03-11db-45b6-bd7f-52505ecd5d72"
      },
      "source": [
        "model.predict(val_ds)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.43096033],\n",
              "       [-1.7075962 ],\n",
              "       [-0.7095792 ],\n",
              "       ...,\n",
              "       [ 0.29161972],\n",
              "       [-0.9264777 ],\n",
              "       [-0.04996577]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk2X1kJkgvmv",
        "outputId": "c5545050-72eb-4b16-e328-6d8118e40fe4"
      },
      "source": [
        "for text_batch, label_batch in val_ds.take(1):\n",
        "  for i in range(5):\n",
        "    print(label_batch[i].numpy(), text_batch.numpy()[i])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 b\"Geordies...salt of the earth characters...bricklayers...beer...Geordies...happy go lucky...adventures working abroad...salt of the earth characters...warm wonderful people...Tyne Bridge (tear in the eye)...brown ale...salt of the earth characters...cute little Red Indians children in Newcastle United tops...emetic...Geordies...salt of the earth characters...<br /><br />etc etc etc....<br /><br />Please. This is so poor. And you should know better Timothy Spall. They can't have paid you that much.<br /><br />As for Jimmy Nail. Well the kindest thing that can be said is that he is every bit as good an 'actor' as he is a singer and writer. Come on Jimmy, the joke's over. 'Crocodile Shoes' and 'Spender' were very funny, unfortunately I don't think they were supposed to be. With 'Auf Wiedersehen Pet' the opposite applies.\"\n",
            "0 b\"My girlfriend picked this one; as a southern born and raised African American I found this movie's plot and premise totally without credibility. To believe that class and racial biases would be so easily and comfortably suspended would only come from someone totally unfamiliar with the ante-bellum south. Totally absurd !!! I wonder how they got a good actor like Harvey Keitel and a good actress like Andie McDowell (who being southern knows better) to participate in this crap\"\n",
            "0 b\"Is this the movie??? Is this what Indians are trying to show?? I think this is one more effort from a sick-minded director to turn down Pakistani soldiers and in fact country....but what we Pakistani's know that we are always ahead of India in every part of our lives...not only in armed counters.<br /><br />Well...this is bad filmed as that of Border in early 1997...and director and writer just tried to overcome a shame of defeat in Kargil by Pakistani armed forces, by creating films like these..<br /><br />One thing is very clear...Whenever there will be an encounter between Pakistan and India....we will win....!!! So Mr. Dutta try to make some good movies instead of Nonsense movies like this\"\n",
            "0 b\"I should say right away that I checked the spoilers box only because I'm giving this comment the amount of thought proportional to what this mess of a movie deserves, and don't want to be held responsible for some plot point incidentally slipping out.<br /><br />This comment will take the form of a tirade for the simple reason that I am still under the influence of this movie, having just watched it, and the unique effect this has renders one incapable of the sort of forethought and paragraph structure required for coherent, reasoned criticism. That is not a compliment. It isn't the narcotic effect of a truly hypnotic or thought provoking movie. The feelings it stirs up combine like some uncomfortable emotional Voltron, composed of a confusing mix of some form of rage, the vague desire to take a shower, the rudderless, sinking feeling of true betrayal one gets when they realize they have given 109 minutes of their lives into the hands of someone who would not only squander it, but do so in such a pompous, artless way. And I probably wouldn't have done anything super productive with that 109 minutes anyway! But even if I'd spent it on something trivial, like a power block of masturbation and online poker, I would have felt more fulfilled when all was said and done.<br /><br />The problems with this movie are myriad, and in better times I'd articulate exactly what they were in a semi-adult fashion. But in keeping with what this movie deserves, I think I'll most likely stick to the realm of masturbation jokes and cartoon references.<br /><br />The most irritating and terminal flaw is that while watching this movie one is keenly aware that the makers and participants think they are making a much smarter movie than they are. Demonstrating the depth of knowledge one could pick up in a one semester survey of Western art history at a community college or trade school, the art-jargon is piled on thick and from all directions, with much of it supplied by talk between our hero, the tortured detective Stan (Willem Dafoe, who I will forgive for this movie due to him being Willem Dafoe) and his accented antique dealer buddy Blair (Peter Stormare, taking a break from playing a sociopath for whom murder comes easy by playing a 2-dimensional plot device in a movie about a sociopath for whom murder comes easy). And talk they do. In fact, we are dropped into this story at a crime scene that may indicate the reemergence of a serial killer Stan thinks he killed years earlier, so all the back story is established partially through unclear flashback, but primarily through stilted conversations between Stan and his dealer, or Stan and his colleague, the unforgivably irritating Carl (Scott Speedman). And although I differentiate the character Carl (Scott Speedman) from the actor who plays him by using parentheses, I must admit that very early on in the film I despised this character so much that I actually found myself sincerely wishing harm on the actor portraying him (Scott Speedman). Not anything too fancy. Not death or paralysis, necessarily.. But maybe herpes? Or maybe a stage light could fall on him and crush his arm? This is a dangerous digression, but I'm not editing it out because I want to leave anyone reading this who's thinking about paying to see this train wreck of a movie with a clear impression of the horrible wishes and feelings it stirs in even the most peaceful man.<br /><br />Well, I'm sort of running out of steam here.. over the course of writing this the sick feelings this movie brought up in a me have subsided, my head has cleared a bit. Realizing now that I'm still investing time in something related to this piece of sh!t is startlingly similar to waking up after a night of suicidally heavy drinking next to the heaving form of a still slumbering 200 pound college girl. Your first urge is a desperate desire to flee. This is natural.\"\n",
            "1 b'Someone(or, something thing..)is leaving puncture marks on the jugular and draining victims of their blood till dead. Police detective Karl Brettschneider(Melvyn Douglas, before slipping out of the B-movie horror genre for greater heights)is stumped at who..or what..is behind these notorious crimes. The village is overcome by hysteria and Karl depends on his trusted medical genius, Dr. Otto von Niemann(Lionel Atwill, in yet another effective mad scientist role)to provide some feedback as to what might be causing the deaths of innocents. He also fears for the safety of his beloved Ruth(the lovely Fay Wray who stars for the third time with Atwill after \"Doctor X\" & \"The Mystery of the Wax Museum\")who is Niemann\\'s assistant.<br /><br />Dwight Frye steals the film as a rather loony village idiot who collects bats and carries a demented demeanor wherever he goes..it\\'s easy to see why he becomes a suspect as local paranoia is at a fever pitch. Maude Eburne provides the film\\'s humor as a very naive(..and easily influenced)patient of von Niemann\\'s who believes she has ailments she reads about in books near the laboratory where he works. She\\'s impressionable and often von Niemann just humors her and constant fictional illnesses she feels plagued with. Lionel Belmore returns as yet another frightened, superstitious B\\xc3\\xbcrgermeister.<br /><br />Creaky, static, but rather entertaining nonetheless thanks to the cast. The film is obviously as low-budget as they come, but this doesn\\'t hurt the film too much since it\\'s put together rather well by director Frank R Strayer and his crew. I\\'m certain the film\\'s print has seen better days, though. This is the kind of B-horror item you\\'d find packaged in with 50 other random cheesefests and poverty row programmers. The film\\'s villain..and his motives for feeding a synthetically made biological creature..certainly provides a different take on the Frankenstein formula. Many might be disappointed with the end results as the film strays away from being an actual supernatural tale about a real vampire killer causing the murders.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBgSoaGmg7O2",
        "outputId": "4b01a432-ce6a-43a8-8de7-68255710fa50"
      },
      "source": [
        "model.predict(tf.constant([b'I dont like this film', b'I love this movie']))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2849543 ],\n",
              "       [0.63746315]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyLWpEddhsHL",
        "outputId": "58674296-ff2a-4a91-ed8c-d23030ad7ee5"
      },
      "source": [
        "ss = tf.constant([b'I dont like this film', b'I love this movie'])\n",
        "##vectorize_layer(ss)\n",
        "layer1 = model.get_layer('text_vectorization')(ss)\n",
        "layer1"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 100), dtype=int64, numpy=\n",
              "array([[ 10,  89,  38,  11,  19,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 10, 116,  11,  17,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqxtJoJKiYCV",
        "outputId": "19d0bf78-8d18-439d-b266-e7efc14226ad"
      },
      "source": [
        "print(vocab_size)\n",
        "print(embedding_dim)\n",
        "\n",
        "## a = Embedding(vocab_size, embedding_dim, name=\"embedding\")(vectorize_layer(ss))\n",
        "##Embedding(vocab_size, embedding_dim, name=\"embedding\")(vectorize_layer(ss))[0,98]\n",
        "layer2 = model.get_layer('embedding')(layer1)\n",
        "layer2"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 100, 16), dtype=float32, numpy=\n",
              "array([[[ 0.11760825,  0.04184723,  0.03735889, ..., -0.20425546,\n",
              "          0.06962103, -0.20330435],\n",
              "        [ 0.15820163,  0.17485887,  0.20868492, ...,  0.07375617,\n",
              "         -0.18388687,  0.12241356],\n",
              "        [ 0.19825642,  0.19966199,  0.1615675 , ...,  0.02730391,\n",
              "         -0.10663366, -0.02769051],\n",
              "        ...,\n",
              "        [ 0.01001509,  0.04355507, -0.00952954, ..., -0.06939524,\n",
              "         -0.00096543, -0.07256617],\n",
              "        [ 0.01001509,  0.04355507, -0.00952954, ..., -0.06939524,\n",
              "         -0.00096543, -0.07256617],\n",
              "        [ 0.01001509,  0.04355507, -0.00952954, ..., -0.06939524,\n",
              "         -0.00096543, -0.07256617]],\n",
              "\n",
              "       [[ 0.11760825,  0.04184723,  0.03735889, ..., -0.20425546,\n",
              "          0.06962103, -0.20330435],\n",
              "        [-0.33920172, -0.35084772, -0.3039089 , ..., -0.32715356,\n",
              "          0.303429  , -0.28535125],\n",
              "        [ 0.20119663,  0.1380489 ,  0.20770065, ..., -0.0974393 ,\n",
              "         -0.0608274 , -0.21068983],\n",
              "        ...,\n",
              "        [ 0.01001509,  0.04355507, -0.00952954, ..., -0.06939524,\n",
              "         -0.00096543, -0.07256617],\n",
              "        [ 0.01001509,  0.04355507, -0.00952954, ..., -0.06939524,\n",
              "         -0.00096543, -0.07256617],\n",
              "        [ 0.01001509,  0.04355507, -0.00952954, ..., -0.06939524,\n",
              "         -0.00096543, -0.07256617]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwbbcopdjmmJ",
        "outputId": "be362b41-88cf-4531-935c-2b7f437c859c"
      },
      "source": [
        "layer3 = model.get_layer('global_average_pooling1d')(layer2)\n",
        "layer3"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
              "array([[ 0.01698615,  0.04727929, -0.00255832, -0.01714214,  0.00498878,\n",
              "        -0.02234781, -0.0325641 , -0.01436502,  0.03876136, -0.02291406,\n",
              "         0.02880586,  0.00577334,  0.05146385, -0.06926841, -0.00307234,\n",
              "        -0.07361408],\n",
              "       [ 0.01056595,  0.04106702, -0.00828891, -0.01377343,  0.00970855,\n",
              "        -0.02804866, -0.02731017, -0.01892008,  0.03345799, -0.01770748,\n",
              "         0.02388258,  0.01071072,  0.05597503, -0.07401031,  0.00168974,\n",
              "        -0.0778981 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qVzP97LlSTK",
        "outputId": "83f91563-6e5d-4ee3-93ff-f7cc412d814a"
      },
      "source": [
        "layer4 = model.get_layer('dense')(layer3)\n",
        "layer4"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
              "array([[0.18344551, 0.21790898, 0.20788395, 0.19175656, 0.        ,\n",
              "        0.17805147, 0.4010757 , 0.16178365, 0.16388698, 0.14666528,\n",
              "        0.1633026 , 0.40150064, 0.        , 0.20183529, 0.22510988,\n",
              "        0.3839228 ],\n",
              "       [0.21824163, 0.25404206, 0.2473211 , 0.22982393, 0.        ,\n",
              "        0.21164057, 0.35554224, 0.19344237, 0.1997631 , 0.17715833,\n",
              "        0.19367056, 0.36011574, 0.        , 0.24091136, 0.27020523,\n",
              "        0.3486954 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isvRu_Z6llVP",
        "outputId": "7bb1097c-28f3-4b75-a286-c2bdd30963d0"
      },
      "source": [
        "layer5 = model.get_layer('dense_1')(layer4)\n",
        "layer5"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[0.2849543 ],\n",
              "       [0.63746315]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV48sDo1oLSH",
        "outputId": "452a07f9-cbd9-47c9-d81b-c3cec457cb52"
      },
      "source": [
        "model.predict(ss)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2849543 ],\n",
              "       [0.63746315]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiQbOJZ2WBFY"
      },
      "source": [
        "Visualize the model metrics in TensorBoard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNyLjcoRWEue"
      },
      "source": [
        "```\n",
        "%tensorboard --logdir logs\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvURkGVpXDOy"
      },
      "source": [
        "![embeddings_classifier_accuracy.png](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/embeddings_classifier_accuracy.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCoA6qwqP836"
      },
      "source": [
        "## Retrieve the trained word embeddings and save them to disk\n",
        "\n",
        "Next, retrieve the word embeddings learned during training. The embeddings are weights of the Embedding layer in the model. The weights matrix is of shape `(vocab_size, embedding_dimension)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp5rv01WG2YA"
      },
      "source": [
        "Obtain the weights from the model using `get_layer()` and `get_weights()`. The `get_vocabulary()` function provides the vocabulary to build a metadata file with one token per line. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uamp1YH8RzU"
      },
      "source": [
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8MiCA77X8B8"
      },
      "source": [
        "Write the weights to disk. To use the [Embedding Projector](http://projector.tensorflow.org), you will upload two files in tab separated format: a file of vectors (containing the embedding), and a file of meta data (containing the words)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLIahl9s53XT"
      },
      "source": [
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  if  index == 0: continue # skip 0, it's padding.\n",
        "  vec = weights[index] \n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQyMZWyxYjMr"
      },
      "source": [
        "If you are running this tutorial in [Colaboratory](https://colab.research.google.com), you can use the following snippet to download these files to your local machine (or use the file browser, *View -> Table of contents -> File browser*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUsjQOKMIV2z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "28ed4634-9dd0-476a-f0db-7ed616fb31c2"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception as e:\n",
        "  pass"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_19c5be35-00bd-4852-960f-e004e4ccec34\", \"vectors.tsv\", 1885718)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_66254462-eaf9-4663-87fa-c9d555279d47\", \"metadata.tsv\", 76492)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXLfFA54Yz-o"
      },
      "source": [
        "## Visualize the embeddings\n",
        "\n",
        "To visualize the embeddings, upload them to the embedding projector.\n",
        "\n",
        "Open the [Embedding Projector](http://projector.tensorflow.org/) (this can also run in a local TensorBoard instance).\n",
        "\n",
        "* Click on \"Load data\".\n",
        "\n",
        "* Upload the two files you created above: `vecs.tsv` and `meta.tsv`.\n",
        "\n",
        "The embeddings you have trained will now be displayed. You can search for words to find their closest neighbors. For example, try searching for \"beautiful\". You may see neighbors like \"wonderful\". \n",
        "\n",
        "Note: Experimentally, you may be able to produce more interpretable embeddings by using a simpler model. Try deleting the `Dense(16)` layer, retraining the model, and visualizing the embeddings again.\n",
        "\n",
        "Note: Typically, a much larger dataset is needed to train more interpretable word embeddings. This tutorial uses a small IMDb dataset for the purpose of demonstration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvKiEHjramNh"
      },
      "source": [
        "## Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSgAZpwF5xF_"
      },
      "source": [
        "This tutorial has shown you how to train and visualize word embeddings from scratch on a small dataset.\n",
        "\n",
        "* To train word embeddings using Word2Vec algorithm, try the [Word2Vec](https://www.tensorflow.org/tutorials/text/word2vec) tutorial. \n",
        "\n",
        "* To learn more about advanced text processing, read the [Transformer model for language understanding](https://www.tensorflow.org/tutorials/text/transformer)."
      ]
    }
  ]
}